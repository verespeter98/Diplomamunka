{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Modell és Tokenizer betöltése ---\n",
      "Modell és tokenizer sikeresen betöltve.\n",
      "Modell áthelyezve a következő eszközre: cpu\n",
      "\n",
      "--- 2. Fájl kézi beolvasása: bert_model/FinancialPhraseBank-v1.0/Sentences_AllAgree.txt ---\n",
      "Fájl sikeresen beolvasva. Találatok száma: 2264 minta.\n",
      "\n",
      "--- 3. Tokenizálás és adatok előkészítése ---\n",
      "Minden mondat tokenizálása...\n",
      "DataLoader létrehozva.\n",
      "\n",
      "--- 4. Kiértékelés futtatása (Batch méret: 16) ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 142/142 [07:25<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- 5. Metrikák és Hibaelemzés ---\n",
      "\n",
      "==============================\n",
      "          KIÉRTÉKELÉS BEFEJEZVE\n",
      "==============================\n",
      "Összes minta: 2264\n",
      "Helyes jóslatok: 2240\n",
      "---\n",
      "Accuracy:  98.94%\n",
      "Precision (Weighted): 0.9895\n",
      "Recall (Weighted):    0.9894\n",
      "F1-score (Weighted):  0.9894\n",
      "==============================\n",
      "\n",
      "--- Tévesen Címkézett Mondatok Elemzése ---\n",
      "Összesen 24 téves jóslat. Első 5 mutatása:\n",
      "\n",
      "1. HIBA\n",
      "  Mondat:   Finnish flexible packaging manufacturer Suominen Corporation reports net sales of EUR 54.5 mn in the first quarter of 2008 , compared with EUR 54.3 mn a year earlier .\n",
      "  Valódi:   positive\n",
      "  Jósolt: negative\n",
      "\n",
      "2. HIBA\n",
      "  Mondat:   These moderate but significant changes resulted in a significant 24-32 % reduction in the estimated CVD risk .\n",
      "  Valódi:   positive\n",
      "  Jósolt: negative\n",
      "\n",
      "3. HIBA\n",
      "  Mondat:   Investors will continue being interested in the company 's share although it is not quite cheap , Affarsvarlden said .\n",
      "  Valódi:   positive\n",
      "  Jósolt: neutral\n",
      "\n",
      "4. HIBA\n",
      "  Mondat:   At the end of the review period , Nordic Aluminium 's order book stood at EUR 8.77 mn compared to EUR 7.04 in 2005 .\n",
      "  Valódi:   positive\n",
      "  Jósolt: negative\n",
      "\n",
      "5. HIBA\n",
      "  Mondat:   Return on investment was 16.6 % compared to 15.8 % in 2004 .\n",
      "  Valódi:   positive\n",
      "  Jósolt: negative\n",
      "==============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "TOKENIZER_PATH = \"saved_tokenizer\"\n",
    "MODEL_PATH = \"saved_model\"\n",
    "BATCH_SIZE = 16\n",
    "LOCAL_DATA_FILE = \"FinancialPhraseBank-v1.0/Sentences_AllAgree.txt\" \n",
    "\n",
    "label_map = {\n",
    "    \"positive\": 0,\n",
    "    \"negative\": 1,\n",
    "    \"neutral\": 2\n",
    "}\n",
    "\n",
    "reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "\n",
    "\n",
    "def evaluate_model():\n",
    "    \"\"\"\n",
    "    Betölt egy lokálisan mentett modellt és tokenizert,\n",
    "    hogy kiértékelje egy kézileg beolvasott txt adathalmazon.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"--- 1. Modell és Tokenizer betöltése ---\")\n",
    "    try:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(MODEL_PATH)\n",
    "        print(\"Modell és tokenizer sikeresen betöltve.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Hiba a modell/tokenizer betöltése közben: {MODEL_PATH} és {TOKENIZER_PATH}.\")\n",
    "        print(f\"Hiba: {e}\")\n",
    "        return\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    print(f\"Modell áthelyezve a következő eszközre: {device}\")\n",
    "\n",
    "    print(f\"\\n--- 2. Fájl kézi beolvasása: {LOCAL_DATA_FILE} ---\")\n",
    "    \n",
    "    sentences = []\n",
    "    labels = []\n",
    "    \n",
    "    try:\n",
    "        with open(LOCAL_DATA_FILE, 'r', encoding='latin-1') as f:\n",
    "            for line in f:\n",
    "                line = line.strip() \n",
    "                if not line:\n",
    "                    continue\n",
    "                \n",
    "                parts = line.split('@')\n",
    "                \n",
    "                if len(parts) == 2:\n",
    "                    sentence_text = parts[0]\n",
    "                    label_text = parts[1]\n",
    "                    \n",
    "                    if label_text in label_map:\n",
    "                        sentences.append(sentence_text)\n",
    "                        labels.append(label_map[label_text])\n",
    "                    else:\n",
    "                        print(f\"Figyelmeztetés: Ismeretlen címkéjű sor kihagyása: {line}\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"Figyelmeztetés: Hibás formátumú sor kihagyása: {line}\")\n",
    "\n",
    "        print(f\"Fájl sikeresen beolvasva. Találatok száma: {len(sentences)} minta.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Hiba: A fájl nem található: {LOCAL_DATA_FILE}\")\n",
    "        return\n",
    "    except Exception as e:\n",
    "        print(f\"Hiba a fájl olvasása vagy feldolgozása közben: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- 3. Tokenizálás és adatok előkészítése ---\")\n",
    "\n",
    "    print(\"Minden mondat tokenizálása...\")\n",
    "    tokenized_inputs = tokenizer(\n",
    "        sentences,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    label_tensors = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "    test_dataset = TensorDataset(\n",
    "        tokenized_inputs['input_ids'],\n",
    "        tokenized_inputs['attention_mask'],\n",
    "        label_tensors\n",
    "    )\n",
    "\n",
    "    # shuffle=False kulcsfontosságú, hogy a sorrend megmaradjon!\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "    print(\"DataLoader létrehozva.\")\n",
    "\n",
    "    print(f\"\\n--- 4. Kiértékelés futtatása (Batch méret: {BATCH_SIZE}) ---\")\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "            \n",
    "            input_ids = batch[0].to(device)\n",
    "            attention_mask = batch[1].to(device)\n",
    "            labels_batch = batch[2].to(device) \n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            predictions = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(predictions.cpu().numpy())\n",
    "            all_labels.extend(labels_batch.cpu().numpy())\n",
    "\n",
    "    print(\"\\n--- 5. Metrikák és Hibaelemzés ---\")\n",
    "    \n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    precision = precision_score(all_labels, all_preds, average='weighted')\n",
    "    recall = recall_score(all_labels, all_preds, average='weighted')\n",
    "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*30)\n",
    "    print(f\"          KIÉRTÉKELÉS BEFEJEZVE\")\n",
    "    print(\"=\"*30)\n",
    "    print(f\"Összes minta: {len(all_labels)}\")\n",
    "    print(f\"Helyes jóslatok: {np.sum(np.array(all_labels) == np.array(all_preds))}\")\n",
    "    print(\"---\")\n",
    "    print(f\"Accuracy:  {accuracy * 100:.2f}%\")\n",
    "    print(f\"Precision (Weighted): {precision:.4f}\")\n",
    "    print(f\"Recall (Weighted):    {recall:.4f}\")\n",
    "    print(f\"F1-score (Weighted):  {f1:.4f}\")\n",
    "    print(\"=\"*30)\n",
    "\n",
    "    print(\"\\n--- Tévesen Címkézett Mondatok Elemzése ---\")\n",
    "    \n",
    "    wrongly_labeled = []\n",
    "\n",
    "    for i in range(len(all_labels)):\n",
    "        true_label = all_labels[i]\n",
    "        pred_label = all_preds[i]\n",
    "        \n",
    "        if true_label != pred_label:\n",
    "            wrongly_labeled.append({\n",
    "                \"sentence\": sentences[i],\n",
    "                \"true_label\": reverse_label_map[true_label], \n",
    "                \"predicted_label\": reverse_label_map[pred_label]\n",
    "            })\n",
    "\n",
    "    if not wrongly_labeled:\n",
    "        print(\"Minden minta helyesen lett címkézve! Nincs hiba.\")\n",
    "    else:\n",
    "        print(f\"Összesen {len(wrongly_labeled)} téves jóslat. Első 5 mutatása:\")\n",
    "        \n",
    "        # Kiíratjuk az első 5-öt (vagy kevesebbet, ha nincs annyi)\n",
    "        for i, item in enumerate(wrongly_labeled[:5]):\n",
    "            print(f\"\\n{i+1}. HIBA\")\n",
    "            print(f\"  Mondat:   {item['sentence']}\")\n",
    "            print(f\"  Valódi:   {item['true_label']}\")\n",
    "            print(f\"  Jósolt: {item['predicted_label']}\")\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
